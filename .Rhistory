setwd("~/Desktop/sem 2/Applied data science/Spr2017-proj5-grp14/data")
train <- read.csv("train.csv", header = T, as.is = T)
train.labels <- train$is_duplicate[train.index]
rf_train=function(data, label) {
t.start <- Sys.time()
library(data.table)
library(dplyr)
library(randomForest)
### Train with decision model
#data=data.frame(data)
#data=mutate(data,label=factor(label))
rf_fit <- randomForest(x = data, y = as.factor(label), ntree = 1000, mty = sqrt(ncol(data)))
#rf_fit <- randomForest(label~ .,data=data,importance=TRUE,ntree=ntree,nodesize, =node,mtry=mtry)
t.end <- Sys.time()
t <- t.start - t.end
return(rf_fit)
}
fit <- rf_train(train.data, train.label)
train.data <- df[s != i,]
train.label <- label[s != i]
test.data <- df[s == i,]
test.label <- label[s == i]
fit <- rf_train(train.data, train.label)
rf_fit <- randomForest(x = data, y = as.factor(label), ntree = 1000, mty = sqrt(ncol(data)))
label <- train.label
length(label)
feature <- read.csv("allfeatures.csv", fill=TRUE, header = TRUE, stringsAsFactors = FALSE)
setwd("~/Desktop/sem 2/Applied data science/Spr2017-proj5-grp14/output")
length(label)
feature <- read.csv("allfeatures.csv", fill=TRUE, header = TRUE, stringsAsFactors = FALSE)
feature <- feature[, -1]
feature <- as.data.frame(feature)
setwd("~/Desktop/sem 2/Applied data science/Spr2017-proj5-grp14/data")
label <- read.csv("~/Desktop/sem 2/Applied data science/Spr2017-proj5-grp14/data/train.csv")
label <- label$is_duplicate
label <- label[1:50000]
set.seed(426)
S <- 50000
train.index <- sample(1:S, 10000)
train.model <- feature[train.index, ]
train.labels <- label$is_duplicate[train.index]
train.labels <- label[train.index]
rf.cv.function <- function(df, labal, K = 5){
n <- length(train.index)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
for (i in 1:K){
train.data <- df[s != i,]
train.label <- label[s != i]
test.data <- df[s == i,]
test.label <- label[s == i]
fit <- rf_train(train.data, train.label)
pred <- rf_test(fit, test.data)
cv.error[i] <- mean(pred != test.label)
}
return(cv.error)
#return(mean(cv.error))
}
nrow(train.model)
length(train.labels)
rf.cv.function(train.model, train.labels)
train.data <- train.model[s != i,]
train.label <- train.labels[s != i]
i
test.data <- train.model[s == i,]
test.label <- train.labels[s == i]
fit <- rf_train(train.data, train.label)
pred <- rf_test(fit, test.data)
cv.error[i] <- mean(pred != test.label)
mean(pred != test.label)
nn <- neuralnet(f, train[,1:16], hidden = c(2, 2, 2), linear.output = FALSE)
library(MASS)
library(caTools)
library(neuralnet)
library(caTools)
library(neuralnet)
maxs <- apply(abs(feature), 2, max)
mins <- apply(abs(feature), 2, min)
scaled.data <- as.data.frame(scale(feature, center = mins, scale = (maxs - mins)))
data = cbind(label, scaled.data)
names(data)[1] <- "classified"
set.seed(426)
split = sample.split(data$classified, SplitRatio = 0.75)
train = subset(data, split == TRUE)
test = subset(data, split == FALSE)
feats <- names(scaled.data)
f <- paste(feats,collapse=' + ')
f <- paste('classified ~',f)
f <- as.formula(f)
nn <- neuralnet(f, train[,1:16], hidden = c(2, 2, 2), linear.output = FALSE)
feats <- names(scaled.data)[1:17]
f <- paste(feats,collapse=' + ')
f <- paste('classified ~',f)
f <- as.formula(f)
nn <- neuralnet(f, train[,1:17], hidden = c(2, 2, 2), linear.output = FALSE)
feats
feats <- names(scaled.data)[1:16]
f <- paste(feats,collapse=' + ')
f <- paste('classified ~',f)
f <- as.formula(f)
nn <- neuralnet(f, train[,1:17], hidden = c(2, 2, 2), linear.output = FALSE)
nn <- neuralnet(f, train[1:5000,1:17], hidden = c(2, 2, 2), linear.output = FALSE)
head(train[,1:16])
nn <- neuralnet(f, train[1:2000,1:17], hidden = c(2, 2, 2), linear.output = FALSE)
cv.error
rf.cv.function <- function(K = 5){
n <- length(train.index)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
for (i in 1:K){
train.data <- train.model[s != i,]
train.label <- train.labels[s != i]
test.data <- train.model[s == i,]
test.label <- train.labels[s == i]
fit <- rf_train(train.data, train.label)
pred <- rf_test(fit, test.data)
cv.error[i] <- mean(pred != test.label)
}
return(cv.error)
#return(mean(cv.error))
}
rf.cv.function()
rf_result <- c(0.2800, 0.2665, 0.2640, 0.2520, 0.2780)
mean(rf_result)
test.index <- 1:S[-train.index]
test.model <- fea[test.index,]
rf_predict <- as.numeric(as.vector(predict(rf_result, test.model)))
resize
?resize
setwd("~/Desktop/sem 2/Applied data science/spr2017-proj3-group-12/data")
source("http://bioconductor.org/biocLite.R")
biocLite("EBImage")
bin_dir <- "~/Desktop/sem 2/Applied data science/Proj3/training_data/bin_image"
n_files <- length(list.files(bin_dir))
file_names <- list.files(bin_dir, pattern = "[[:digit:]]_bin.jpg")
file_paths <- rep(NA_character_, length(file_names))
for (i in 1:length(file_names)) {
file_paths[i] <- paste(bin_dir, file_names[i], sep = "/")
}
file_paths <- sort(file_paths)
location_feature <- matrix(NA, nrow = 64*64, ncol = n_files)
i=1
img_bw <- readImage(file_paths[i])
library(EBImage)
n
img_bw <- readImage(file_paths[i])
img_bw
mat <- imageData(img_gray)
mat <- imageData(bw)
img_gray <- readImage(file_paths[i])
mat <- imageData(img_gray)
dim(mat)
im <- img.resize(img_gray)
im <- resize(img_gray, 100,100)
mat2 <- imageData(im)
dim(mat2)
View(mat)
View(mat2)
set.seed(426)
S <- 50000
train.index <- sample(1:S, S*0.6)
train.model <- feature[train.index, ]
train.labels <- label[train.index]
RandomForestExploration = function() {
features <- train.model
label <- train.labels
rf_result <- randomForest(x = features, y = as.factor(label), ntree = 1500)
best_ntree <- which.min(rf_result$err.rate[,"OOB"])
err_rate <- c(rf_result$err.rate[100, "OOB"], rf_result$err.rate[500, "OOB"]
, rf_result$err.rate[1000, "OOB"], rf_result$err.rate[1500, "OOB"])
names(err_rate) <- c("100", "500", "1000", "1500")
image <- plot(x = c(1:1500), y = rf_result$err.rate[,"OOB"], main = "Validation Error for Random Forest", xlab = "Number of Trees", ylab = "Validation Error")
return(image)
}
RandomForestExploration()
set.seed(426)
S <- 50000
train.index <- sample(1:S, S*0.6)
train.data <- feature[train.index, ]
train.labels <- label[train.index]
rf_train=function(data, label) {
### Train with decision model
rf_fit <- randomForest(x = data, y = as.factor(label), ntree = 1000, mty = sqrt(ncol(data)))
return(rf_fit)
}
rf_test <- function(fit_train, dat_test){
pred <- predict(fit_train, newdata=dat_test)
return(pred)
}
rf_model <- rf_train(train.data, train.labels)
test.data <- feature[-train.index, ]
rf_model <- rf_train(train.data, train.labels)
feature <- read.csv("../output/allfeatures.csv", fill=TRUE, header = TRUE, stringsAsFactors = FALSE)
set.seed(426)
S <- 50000
train.index <- sample(1:S, S*0.6)
train.data <- feature[train.index, ]
train.labels <- label[train.index]
rf_train=function(data, label) {
### Train with decision model
rf_fit <- randomForest(x = data, y = as.factor(label), ntree = 1000, mty = sqrt(ncol(data)))
return(rf_fit)
}
rf_test <- function(fit_train, dat_test){
pred <- predict(fit_train, newdata=dat_test)
return(pred)
}
rf.cv.function <- function(K = 5){
n <- length(train.index)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
for (i in 1:K){
train.d <- train.data[s != i,]
train.l <- train.labels[s != i]
test.d <- train.data[s == i,]
test.l <- train.labels[s == i]
fit <- rf_train(train.d, train.l)
pred <- rf_test(fit, test.d)
cv.error[i] <- mean(pred != test.l)
}
return(cv.error)
#return(mean(cv.error))
}
test.data <- feature[-train.index, ]
rf_model <- rf_train(train.data, train.labels)
rf_predict <- rf_test(rf_model, test.data)
rf_predict
test.label <- label[-train.index]
err <- mean(rf_predict != test.label
t.start <- Sys.time()
t.end <- Sys.time()
t <- t.start - t.end
err <- mean(rf_predict != test.label)
err
t.start <- Sys.time()
test.data <- feature[-train.index, ]
test.label <- label[-train.index]
rf_model <- rf_train(train.data, train.labels)
rf_predict <- rf_test(rf_model, test.data)
err <- mean(rf_predict != test.label)
t.end <- Sys.time()
t <- t.start - t.end
t
t <- t.end - t.start
t
t.start
t.end
y <- read.csv("../data/train.csv")
setwd("~/Desktop/sem 2/Applied data science/Spr2017-proj5-grp14")
X = X[20:50,1:100]
X = X[20:50,1:100]
y <- read.csv("../data/train.csv")
y <- read.csv("~/Desktop/sem 2/Applied data science/Spr2017-proj5-grp14/data/train.csv")
y <- y$is_duplicate
y <- y[1:50000]
oriData <- read.csv("~/Desktop/sem 2/Applied data science/Spr2017-proj5-grp14/output/allfeatures.csv", fill=TRUE, header = TRUE, stringsAsFactors = FALSE)
X <- oriData
n_feature <- ncol(X)
n_case <- nrow(X)
y = ifelse(y==0,-1,y)
X = X[20:50,1:100]
y = y[1:100]
X.1 = X[1000:1039,1:100]
y.1 = y[1:100,]
t <- (t.start - t.end)*60
t
rf_result
err_rf_test <- mean(rf_predict != test.label)
err_rf_train <- rf_test(rf_model, train.data)
err_rf_test
err_rf_train
train_pred <- rf_test(rf_model, train.data)
err_rf_train <- mean(train_pred != train.labels)
err_rf_test <- mean(rf_predict != test.label)
err_rf_train
err_rf_test
install.packages("lars")
library(lars)
library(lars)
library(glmnet)
install.packages("flmnet")
install.packages("flmnet")
install.packages("glmnet")
library(glmnet)
library(glmnet)
`%ni%`<-Negate(`%in%`)
View(feature)
View(data)
x <- model.matrix(classified~.,data=data)
View(x)
x
data(mtcars)
x<-model.matrix(mpg~.,data=mtcars)
x
head(mtcars)
head(data)
x <- model.matrix(classified~.,data=data)
x<-model.matrix(mpg~.,data=mtcars)
x <- cbind(rep(1, nrow(data)), feature)
glmnet1<-cv.glmnet(x=x,y=data$classified, type.measure='mse', nfolds=5, alpha=.5)
head(x)
glmnet1<-cv.glmnet(x=x,y=label, type.measure='mse', nfolds=5, alpha=.5)
mode(x)
mode(feature)
x <- cbind(rep(1, nrow(data)), as.matrix(feature))
glmnet1<-cv.glmnet(x=x,y=label, type.measure='mse', nfolds=5, alpha=.5)
c<-coef(glmnet1,s='lambda.min',exact=TRUE)
inds<-which(c!=0)
variables<-row.names(c)[inds]
variables<-variables[variables %ni% '(Intercept)']
variables
c<-coef(glmnet1,s='lambda.min',exact=TRUE)
c
sort(abs(c))
sort(abs(c), decreasing = T)
fea_sel <- sort(abs(c), decreasing = T)[21]
fea_sel <- sort(abs(c), decreasing = T)
sort(abs(c), decreasing = T)
fea_sel
fea_sel <- sort(abs(c), decreasing = T)[21]
fea_sel
inds<-which(c > fea_sel)
variables<-row.names(c)[inds]
Intercept <- rep(1, nrow(data))
x <- cbind(Intercept, as.matrix(feature))
names(x)[1:4]
x <- cbind(Intercept, as.matrix(feature))
names(x)
View(x)
x <- data.frame(Intercept, as.matrix(feature))
glmnet1<-cv.glmnet(x=x,y=label, type.measure='mse', nfolds=5, alpha=.5)
x <- data.frame(Intercept, as.matrix(feature))
glmnet1<-cv.glmnet(x=x,y=label, type.measure='mse', nfolds=5, alpha=.5)
x <- cbind(Intercept, as.matrix(feature)
glmnet1<-cv.glmnet(x=x,y=label, type.measure='mse', nfolds=5, alpha=.5)
c<-coef(glmnet1,s='lambda.min',exact=TRUE)
fea_sel <- sort(abs(c), decreasing = T)[21]
inds<-which(c > fea_sel)
variables<-row.names(c)[inds]
variables<-variables[variables %ni% '(Intercept)']
variables
x <- cbind(Intercept, as.matrix(feature)
glmnet1<-cv.glmnet(x=x,y=label, type.measure='mse', nfolds=5, alpha=.5)
c<-coef(glmnet1,s='lambda.min',exact=TRUE)
fea_sel <- sort(abs(c), decreasing = T)[21]
inds<-which(c > fea_sel)
variables<-row.names(c)[inds]
variables<-variables[variables %ni% '(Intercept)']
variables
x <- cbind(Intercept, as.matrix(feature))
glmnet1<-cv.glmnet(x=x,y=label, type.measure='mse', nfolds=5, alpha=.5)
c<-coef(glmnet1,s='lambda.min',exact=TRUE)
fea_sel <- sort(abs(c), decreasing = T)[21]
inds<-which(c > fea_sel)
variables<-row.names(c)[inds]
variables
fea_sel
inds<-which(c > fea_sel)
inds
inds<-which(abs(c) > fea_sel)
inds
inds<-which(abs(c) > fea_sel)
variables<-row.names(c)[inds]
variables<-variables[variables %ni% '(Intercept)']
variables
inds
err_rf_train
err_rf_test
rf_model <- rf_train(train.data[, inds], train.labels)
rf_predict <- rf_test(rf_model, test.data)
train_pred <- rf_test(rf_model, train.data)
err_rf_train <- mean(train_pred != train.labels)
err_rf_test <- mean(rf_predict != test.label)
err_rf_train
err_rf_test
names(train.data)
names(train.data)[inds]
variables
inds
variables<-row.names(c)[inds]
variables
row.names(c)[inds]
row.names(c)
x <- as.matrix(feature)
x <- as.matrix(feature)
glmnet1<-cv.glmnet(x=x,y=label, type.measure='mse', nfolds=5, alpha=.5)
c<-coef(glmnet1,s='lambda.min',exact=TRUE)
fea_sel <- sort(abs(c), decreasing = T)[21]
inds<-which(abs(c) > fea_sel)
inds
variables<-row.names(c)[inds]
variables<-variables[variables %ni% '(Intercept)']
variables
row.names(c)[inds]
t.inds <- inds[-1]-1
names(data)[t.inds]
t.inds <- inds[-1]
names(data)[t.inds]
rf_model <- rf_train(train.data[, t.inds], train.labels)
rf_predict <- rf_test(rf_model, test.data)
train_pred <- rf_test(rf_model, train.data)
err_rf_train <- mean(train_pred != train.labels)
err_rf_test <- mean(rf_predict != test.label)
err_rf_train
err_rf_test
t.inds
names(train.data[, t.inds])
variables
t.inds <- inds[-1]-1
names(train.data)[t.inds]
rf_model <- rf_train(train.data[, t.inds], train.labels)
rf_predict <- rf_test(rf_model, test.data)
train_pred <- rf_test(rf_model, train.data)
err_rf_train <- mean(train_pred != train.labels)
err_rf_test <- mean(rf_predict != test.label)
err_rf_train
err_rf_test
rf_model <- rf_train(train.data, train.labels)
rf_predict <- rf_test(rf_model, test.data)
train_pred <- rf_test(rf_model, train.data)
err_rf_train <- mean(train_pred != train.labels)
err_rf_test <- mean(rf_predict != test.label)
err_rf_train
err_rf_test
library(data.table)
library(dplyr)
library(randomForest)
feature <- read.csv("~/Desktop/sem 2/Applied data science/Spr2017-proj5-grp14/output/allfeatures.csv", fill=TRUE, header = TRUE, stringsAsFactors = FALSE)
feature <- feature[, -1]
label <- read.csv("~/Desktop/sem 2/Applied data science/Spr2017-proj5-grp14/data/train.csv")
label <- label$is_duplicate
S <- 50000
label <- label[1:S]
train.index <- sample(1:S, S*0.75)
train.data <- feature[train.index, ]
train.labels <- label[train.index]
RandomForestExploration = function() {
features <- train.data
label <- train.labels
rf_result <- randomForest(x = features, y = as.factor(label), ntree = 1500)
best_ntree <- which.min(rf_result$err.rate[,"OOB"])
err_rate <- c(rf_result$err.rate[100, "OOB"], rf_result$err.rate[500, "OOB"]
, rf_result$err.rate[1000, "OOB"], rf_result$err.rate[1500, "OOB"])
names(err_rate) <- c("100", "500", "1000", "1500")
image <- plot(x = c(1:1500), y = rf_result$err.rate[,"OOB"], main = "Validation Error for Random Forest", xlab = "Number of Trees", ylab = "Validation Error")
return(image)
}
RandomForestExploration()
train.index <- sample(1:S, S*0.75)
train.data <- feature[train.index, ]
train.labels <- label[train.index]
features <- train.data
label <- train.labels
rf_result <- randomForest(x = features, y = as.factor(label), ntree = 1500)
RandomForesTrain <- function(data, label) {
### Train with decision model
rf_fit <- randomForest(x = data, y = as.factor(label), ntree = 1000, mty = sqrt(ncol(data)))
return(rf_fit)
}
RandomForestTest <- function(fit_train, dat_test){
pred <- predict(fit_train, newdata=dat_test)
return(pred)
}
RandomForestCV <- function(K = 5){
n <- length(S)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
for (i in 1:K){
train.d <- feature[s != i,]
train.l <- label[s != i]
test.d <- feature[s == i,]
test.l <- label[s == i]
fit <- RandomForesTrain(train.d, train.l)
pred <- RandomForestTest(fit, test.d)
cv.error[i] <- mean(pred != test.l)
}
return(mean(cv.error))
}
test.data <- feature[-train.index, ]
test.label <- label[-train.index]
rf_model <- RandomForesTrain(train.data, train.labels)
name1 <- c("len.1", "len.2", "rem.len.1", "rem.len.2", "num.same", "len.ratio", "len.v.1", "len.v.2", "len.n.1"
, "len.n.2", "rem.len.v.1", "rem.len.v.2", "rem.len.n.1", "rem.len.n.2", "v.ratio", "n.ratio")
best_ntree <- which.min(rf_result$err.rate[,"OOB"])
rf_predict <- RandomForestTest(rf_model, test.data)
train_pred <- RandomForestTest(rf_model, train.data)
err_rf_train <- mean(train_pred != train.labels)
err_rf_test <- mean(rf_predict != test.label)
save(rf_model, file = "rf_para.RData")
name1 <- c("len.1", "len.2", "rem.len.1", "rem.len.2", "num.same", "len.ratio", "len.v.1", "len.v.2", "len.n.1"
, "len.n.2", "rem.len.v.1", "rem.len.v.2", "rem.len.n.1", "rem.len.n.2", "v.ratio", "n.ratio")
feature <- read.csv("~/Desktop/sem 2/Applied data science/Spr2017-proj5-grp14/output/allfeatures.csv", header = TRUE)
length(name1)
View(feature)
names(feature)[2:17] <- name1
View(feature)
length(composition)
composition <- c("CC", "CD", "DT", "EX", "FW", "IN", "JJ", "JJR", "JJS", "LS", "MD", "NN", "NNS", "NNP"
, "NNPS", "PDT", "POS", "PRP", "PRP$", "RB", "RBR", "RBS", "RP", "SYM", "TO", "UH", "VB"
, "VBD", "VBG", "VBN", "VBP", "VBZ", "WDT","WP","WP$","WRB", ".", "-LRB-", "-RRB-", ","
, ":", "''", "``")
length(composition)
names(feature)
112-70+!
1
112-70+1
names(feature)[70:112] <- composition
write.csv(feature, file = "allfeature.csv")
