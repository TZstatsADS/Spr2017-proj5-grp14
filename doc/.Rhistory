knitr::opts_chunk$set(echo = TRUE)
path<-file.path("..","data","InauguralSpeeches")
filenames<-dir(path)
speeches.number<-length(dir(path))
speeches.number
docs<-Corpus(DirSource(path))
library(tm)
docs<-Corpus(DirSource(path))
docs[[1]]
mode(docs)
length(docs)
mode(docs[[1]])
docs[[1]][[1]]
docs[[1]][[2]]
docs[[1]][[3]]
length(docs[[1]])
?Corpus
Q1.doc<-VCorpus(VectorSource(Q1))
Q1.doc
Q1.doc<-Corpus(VectorSource(Q1))
Q1.doc
Q1[[1]]
Q1[[2]]
length(Q1)
length(Q1.doc)
Q1.doc[[2]]
Q1.doc[[1]]
Q1.doc[[1]][[1]]
Q1.doc[[1]][[2]]
Q1.doc[[1]][[3]]
Q1.doc<-VCorpus(VectorSource(Q1))
Q1.doc[[1]][[3]]
Q1.doc[[1]][[2]]
Q1.doc[[1]][[1]]
Q2.doc<-Corpus(VectorSource(Q2))
Q1.doc<-Corpus(VectorSource(Q1))
Q2.doc<-Corpus(VectorSource(Q2))
?tm_map
stopwords()
sent_detect(Q1.doc[[1]][[1]])
library(tidytext)
sent_detect(Q1.doc[[1]][[1]])
library(topicmodels)
sent_detect(Q1.doc[[1]][[1]])
library(qdap)
sent_detect(Q1.doc[[1]][[1]])
?sent_detect
text.count<-function(sent){
text<-sent[[1]]
punc<-length(gregexpr("[.|!|?|;|:|,]",text)[[1]])
modal<-length(gregexpr("will|can|shall|must|should|would|could|may|might",text)[[1]])
neg<-length(gregexpr("never|not|non|rare|no|neither|seldom|hardly",text)[[1]])
return(list(punc=punc,modal=modal,neg=neg))
}
Q1.num<-llply(Q1.doc,text.count)
library(dplyr)
Q1.num<-llply(Q1.doc,text.count)
library(plyr)
Q1.num<-llply(Q1.doc,text.count)
Q1.num[[1]]
Q1.num[[2]]
Q1.num[[3]]
Q1.num[[5]]
Q1.num<-ldply(Q1.num,unlist)
View(Q1.num)
Q2.num<-llply(Q2.doc,text.count)
Q2.num<-llply(Q2.doc,text.count)
Q2.num<-ldply(Q2.num,unlist)
docs.res<-data.frame(stringsAsFactors = FALSE)
docs.res.word<-unnest_tokens(docs.res,word,text)
for(i in 1:58){
docs[[i]][[3]]<-sent_detect(docs[[i]][[1]])
docs[[i]][[4]]<-word_count(docs[[i]][[3]])
docs[[i]][[3]]<-data.frame(text=docs[[i]][[3]],stringsAsFactors = FALSE)
docs[[i]][[3]]$speech.num<-rep(i,nrow(docs[[i]][[3]]))
docs[[i]][[5]]<-unnest_tokens(docs[[i]][[3]],word,text)
if (whether.res[i]) docs.res<-rbind(docs.res,docs[[i]][[3]])
else docs.nres<-rbind(docs.nres,docs[[i]][[3]])
}
docs.nres<-data.frame(stringsAsFactors = FALSE)
for(i in 1:58){
docs[[i]][[3]]<-sent_detect(docs[[i]][[1]])
docs[[i]][[4]]<-word_count(docs[[i]][[3]])
docs[[i]][[3]]<-data.frame(text=docs[[i]][[3]],stringsAsFactors = FALSE)
docs[[i]][[3]]$speech.num<-rep(i,nrow(docs[[i]][[3]]))
docs[[i]][[5]]<-unnest_tokens(docs[[i]][[3]],word,text)
if (whether.res[i]) docs.res<-rbind(docs.res,docs[[i]][[3]])
else docs.nres<-rbind(docs.nres,docs[[i]][[3]])
}
knitr::opts_chunk$set(echo = TRUE)
packages.used=c("tibble","udunits2",
"sentimentr", "dplyr",
"tm",  "beeswarm","RColorBrewer",
"topicmodels","plyr","ggplot2","wordcloud","reshape2","tidytext","stringr","qdap","cowplot","tidyr")
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE,repos = 'http://cran.us.r-project.org')
}
library(tm)
library(plyr)
library(dplyr)
library(ggplot2)
library(wordcloud)
library(topicmodels)
library(reshape2)
library(tidytext)
library(stringr)
library(qdap)
library(beeswarm)
library(shiny)
library(cowplot)
library(tidyr)
library(udunits2)
print(R.version)
path<-file.path("..","data","InauguralSpeeches")
filenames<-dir(path)
speeches.number<-length(dir(path))
speeches.number
docs<-Corpus(DirSource(path))
head(summary(docs),3)
years<-read.csv("../data/InauguationDates.csv",header=TRUE,stringsAsFactors = FALSE)
years.name<-gsub("[ |.]","",years$PRESIDENT)
years.recession<-c(1825,1837,1847,1857,1866,1873,1882:1893,1920,1929:1933,1948:1949,1953:1954,1957:1958,1960:1961,1969:1970,1973:1975,1980:1982,1990:1991,2001:2002,2007:2009)
whether.res<-rep(FALSE,58)
for (i in 1:58) {
n<-nchar(filenames[i])
filenames1<-substr(filenames[i],6,n-6)
j<-which(years.name==filenames1)
time<-years[j,as.numeric(substr(filenames[i],n-4,n-4))+1]
m<-nchar(time)
if (sum(as.numeric(substr(time,m-3,m)) == years.recession) > 0) whether.res[i]<-TRUE
}
sum(whether.res)
58-sum(whether.res)
docs<-tm_map(docs,content_transformer(tolower))
text.count<-function(speeches){
text<-speeches[[1]]
punc<-length(gregexpr("[.|!|?|;]",text)[[1]])
i<-length(gregexpr("i |me |myself |my |mine ",text)[[1]])
we<-length(gregexpr("we |us |ourself|our |ours ",text)[[1]])/i
modal<-length(gregexpr("will|can|shall|must",text)[[1]])/i
return(list(sentence=punc,i=i,we=we,modal=modal))
}
docs<-tm_map(docs,removeNumbers)
docs<-tm_map(docs,stripWhitespace)
text.num<-llply(docs,text.count)
text.num<-ldply(text.num,unlist)
text.num$whether.res<-whether.res
beeswarm(sentence~whether.res,data = text.num,horizontal = F, pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), cex=0.75, cex.axis=0.8, cex.lab=1,spacing=5/2, xlab="whether speech making during a recession",ylab="Number of sentences.")
boxplot(sentence~whether.res,data = text.num, add = T,
names = c("",""), col="#0000ff22",outline=FALSE)
beeswarm(we~whether.res,data = text.num[-44,],horizontal = F, pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), cex=0.75, cex.axis=0.8, cex.lab=1,spacing=5/2,xlab="whether speech making during a recession",ylab="the proportion of we to i")
boxplot(we~whether.res,data = text.num, add = T,
names = c("",""), col="#0000ff22",outline=FALSE)
beeswarm(modal~whether.res,data = text.num,horizontal = F, pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), cex=0.75, cex.axis=0.8, cex.lab=1,spacing=5/2,xlab="whether speech making during a recession",ylab="Number of modals")
boxplot(we~whether.res,data = text.num, add = T,
names = c("",""), col="#0000ff22",outline=FALSE)
docs.res<-data.frame(stringsAsFactors = FALSE)
docs.nres<-data.frame(stringsAsFactors = FALSE)
for(i in 1:58){
docs[[i]][[3]]<-sent_detect(docs[[i]][[1]])
docs[[i]][[4]]<-word_count(docs[[i]][[3]])
docs[[i]][[3]]<-data.frame(text=docs[[i]][[3]],stringsAsFactors = FALSE)
docs[[i]][[3]]$speech.num<-rep(i,nrow(docs[[i]][[3]]))
docs[[i]][[5]]<-unnest_tokens(docs[[i]][[3]],word,text)
if (whether.res[i]) docs.res<-rbind(docs.res,docs[[i]][[3]])
else docs.nres<-rbind(docs.nres,docs[[i]][[3]])
}
knitr::opts_chunk$set(echo = TRUE)
packages.used=c("tibble","udunits2",
"sentimentr", "dplyr",
"tm",  "beeswarm","RColorBrewer",
"topicmodels","plyr","ggplot2","wordcloud","reshape2","tidytext","stringr","qdap","cowplot","tidyr")
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE,repos = 'http://cran.us.r-project.org')
}
library(tm)
library(plyr)
library(dplyr)
library(ggplot2)
library(wordcloud)
library(topicmodels)
library(reshape2)
library(tidytext)
library(stringr)
library(qdap)
library(beeswarm)
library(shiny)
library(cowplot)
library(tidyr)
library(udunits2)
print(R.version)
path<-file.path("..","data","InauguralSpeeches")
filenames<-dir(path)
speeches.number<-length(dir(path))
speeches.number
docs<-Corpus(DirSource(path))
head(summary(docs),3)
years<-read.csv("../data/InauguationDates.csv",header=TRUE,stringsAsFactors = FALSE)
years.name<-gsub("[ |.]","",years$PRESIDENT)
years.recession<-c(1825,1837,1847,1857,1866,1873,1882:1893,1920,1929:1933,1948:1949,1953:1954,1957:1958,1960:1961,1969:1970,1973:1975,1980:1982,1990:1991,2001:2002,2007:2009)
whether.res<-rep(FALSE,58)
for (i in 1:58) {
n<-nchar(filenames[i])
filenames1<-substr(filenames[i],6,n-6)
j<-which(years.name==filenames1)
time<-years[j,as.numeric(substr(filenames[i],n-4,n-4))+1]
m<-nchar(time)
if (sum(as.numeric(substr(time,m-3,m)) == years.recession) > 0) whether.res[i]<-TRUE
}
sum(whether.res)
58-sum(whether.res)
docs<-tm_map(docs,content_transformer(tolower))
text.count<-function(speeches){
text<-speeches[[1]]
punc<-length(gregexpr("[.|!|?|;]",text)[[1]])
i<-length(gregexpr("i |me |myself |my |mine ",text)[[1]])
we<-length(gregexpr("we |us |ourself|our |ours ",text)[[1]])/i
modal<-length(gregexpr("will|can|shall|must",text)[[1]])/i
return(list(sentence=punc,i=i,we=we,modal=modal))
}
docs<-tm_map(docs,removeNumbers)
docs<-tm_map(docs,stripWhitespace)
text.num<-llply(docs,text.count)
text.num<-ldply(text.num,unlist)
text.num$whether.res<-whether.res
beeswarm(sentence~whether.res,data = text.num,horizontal = F, pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), cex=0.75, cex.axis=0.8, cex.lab=1,spacing=5/2, xlab="whether speech making during a recession",ylab="Number of sentences.")
boxplot(sentence~whether.res,data = text.num, add = T,
names = c("",""), col="#0000ff22",outline=FALSE)
beeswarm(we~whether.res,data = text.num[-44,],horizontal = F, pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), cex=0.75, cex.axis=0.8, cex.lab=1,spacing=5/2,xlab="whether speech making during a recession",ylab="the proportion of we to i")
boxplot(we~whether.res,data = text.num, add = T,
names = c("",""), col="#0000ff22",outline=FALSE)
beeswarm(modal~whether.res,data = text.num,horizontal = F, pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), cex=0.75, cex.axis=0.8, cex.lab=1,spacing=5/2,xlab="whether speech making during a recession",ylab="Number of modals")
boxplot(we~whether.res,data = text.num, add = T,
names = c("",""), col="#0000ff22",outline=FALSE)
docs.res<-data.frame(stringsAsFactors = FALSE)
docs.nres<-data.frame(stringsAsFactors = FALSE)
for(i in 1:58){
docs[[i]][[3]]<-sent_detect(docs[[i]][[1]])
docs[[i]][[4]]<-word_count(docs[[i]][[3]])
docs[[i]][[3]]<-data.frame(text=docs[[i]][[3]],stringsAsFactors = FALSE)
docs[[i]][[3]]$speech.num<-rep(i,nrow(docs[[i]][[3]]))
docs[[i]][[5]]<-unnest_tokens(docs[[i]][[3]],word,text)
if (whether.res[i]) docs.res<-rbind(docs.res,docs[[i]][[3]])
else docs.nres<-rbind(docs.nres,docs[[i]][[3]])
}
docs[[3]]
docs[[2]]
docs[[1]]
docs[[4]]
docs<-tm_map(docs,removeNumbers)
knitr::opts_chunk$set(echo = TRUE)
packages.used=c("tibble","udunits2",
"sentimentr", "dplyr",
"tm",  "beeswarm","RColorBrewer",
"topicmodels","plyr","ggplot2","wordcloud","reshape2","tidytext","stringr","qdap","cowplot","tidyr")
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE,repos = 'http://cran.us.r-project.org')
}
library(tm)
library(plyr)
library(dplyr)
library(ggplot2)
library(wordcloud)
library(topicmodels)
library(reshape2)
library(tidytext)
library(stringr)
library(qdap)
library(beeswarm)
library(shiny)
library(cowplot)
library(tidyr)
library(udunits2)
print(R.version)
path<-file.path("..","data","InauguralSpeeches")
filenames<-dir(path)
speeches.number<-length(dir(path))
speeches.number
docs<-Corpus(DirSource(path))
head(summary(docs),3)
years<-read.csv("../data/InauguationDates.csv",header=TRUE,stringsAsFactors = FALSE)
years.name<-gsub("[ |.]","",years$PRESIDENT)
years.recession<-c(1825,1837,1847,1857,1866,1873,1882:1893,1920,1929:1933,1948:1949,1953:1954,1957:1958,1960:1961,1969:1970,1973:1975,1980:1982,1990:1991,2001:2002,2007:2009)
whether.res<-rep(FALSE,58)
for (i in 1:58) {
n<-nchar(filenames[i])
filenames1<-substr(filenames[i],6,n-6)
j<-which(years.name==filenames1)
time<-years[j,as.numeric(substr(filenames[i],n-4,n-4))+1]
m<-nchar(time)
if (sum(as.numeric(substr(time,m-3,m)) == years.recession) > 0) whether.res[i]<-TRUE
}
sum(whether.res)
58-sum(whether.res)
docs<-tm_map(docs,content_transformer(tolower))
docs<-tm_map(docs,content_transformer(tolower))
docs<-tm_map(docs,content_transformer(tolower))
text.count<-function(speeches){
text<-speeches[[1]]
punc<-length(gregexpr("[.|!|?|;]",text)[[1]])
i<-length(gregexpr("i |me |myself |my |mine ",text)[[1]])
we<-length(gregexpr("we |us |ourself|our |ours ",text)[[1]])/i
modal<-length(gregexpr("will|can|shall|must",text)[[1]])/i
return(list(sentence=punc,i=i,we=we,modal=modal))
}
docs<-tm_map(docs,removeNumbers)
docs<-tm_map(docs,stripWhitespace)
docs.res<-data.frame(stringsAsFactors = FALSE)
docs.nres<-data.frame(stringsAsFactors = FALSE)
for(i in 1:58){
docs[[i]][[3]]<-sent_detect(docs[[i]][[1]])
docs[[i]][[4]]<-word_count(docs[[i]][[3]])
docs[[i]][[3]]<-data.frame(text=docs[[i]][[3]],stringsAsFactors = FALSE)
docs[[i]][[3]]$speech.num<-rep(i,nrow(docs[[i]][[3]]))
docs[[i]][[5]]<-unnest_tokens(docs[[i]][[3]],word,text)
if (whether.res[i]) docs.res<-rbind(docs.res,docs[[i]][[3]])
else docs.nres<-rbind(docs.nres,docs[[i]][[3]])
}
knitr::opts_chunk$set(echo = TRUE)
packages.used=c("tibble","udunits2",
"sentimentr", "dplyr",
"tm",  "beeswarm","RColorBrewer",
"topicmodels","plyr","ggplot2","wordcloud","reshape2","tidytext","stringr","qdap","cowplot","tidyr")
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE,repos = 'http://cran.us.r-project.org')
}
library(tm)
library(plyr)
library(dplyr)
library(ggplot2)
library(wordcloud)
library(topicmodels)
library(reshape2)
library(tidytext)
library(stringr)
library(qdap)
library(beeswarm)
library(shiny)
library(cowplot)
library(tidyr)
library(udunits2)
print(R.version)
path<-file.path("..","data","InauguralSpeeches")
filenames<-dir(path)
speeches.number<-length(dir(path))
speeches.number
docs<-Corpus(DirSource(path))
head(summary(docs),3)
years<-read.csv("../data/InauguationDates.csv",header=TRUE,stringsAsFactors = FALSE)
years.name<-gsub("[ |.]","",years$PRESIDENT)
years.recession<-c(1825,1837,1847,1857,1866,1873,1882:1893,1920,1929:1933,1948:1949,1953:1954,1957:1958,1960:1961,1969:1970,1973:1975,1980:1982,1990:1991,2001:2002,2007:2009)
whether.res<-rep(FALSE,58)
for (i in 1:58) {
n<-nchar(filenames[i])
filenames1<-substr(filenames[i],6,n-6)
j<-which(years.name==filenames1)
time<-years[j,as.numeric(substr(filenames[i],n-4,n-4))+1]
m<-nchar(time)
if (sum(as.numeric(substr(time,m-3,m)) == years.recession) > 0) whether.res[i]<-TRUE
}
sum(whether.res)
58-sum(whether.res)
docs<-tm_map(docs,content_transformer(tolower))
text.count<-function(speeches){
text<-speeches[[1]]
punc<-length(gregexpr("[.|!|?|;]",text)[[1]])
i<-length(gregexpr("i |me |myself |my |mine ",text)[[1]])
we<-length(gregexpr("we |us |ourself|our |ours ",text)[[1]])/i
modal<-length(gregexpr("will|can|shall|must",text)[[1]])/i
return(list(sentence=punc,i=i,we=we,modal=modal))
}
docs<-tm_map(docs,removeNumbers)
docs<-tm_map(docs,stripWhitespace)
text.num<-llply(docs,text.count)
text.num<-ldply(text.num,unlist)
text.num$whether.res<-whether.res
beeswarm(sentence~whether.res,data = text.num,horizontal = F, pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), cex=0.75, cex.axis=0.8, cex.lab=1,spacing=5/2, xlab="whether speech making during a recession",ylab="Number of sentences.")
boxplot(sentence~whether.res,data = text.num, add = T,
names = c("",""), col="#0000ff22",outline=FALSE)
beeswarm(we~whether.res,data = text.num[-44,],horizontal = F, pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), cex=0.75, cex.axis=0.8, cex.lab=1,spacing=5/2,xlab="whether speech making during a recession",ylab="the proportion of we to i")
boxplot(we~whether.res,data = text.num, add = T,
names = c("",""), col="#0000ff22",outline=FALSE)
beeswarm(modal~whether.res,data = text.num,horizontal = F, pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), cex=0.75, cex.axis=0.8, cex.lab=1,spacing=5/2,xlab="whether speech making during a recession",ylab="Number of modals")
boxplot(we~whether.res,data = text.num, add = T,
names = c("",""), col="#0000ff22",outline=FALSE)
docs.res<-data.frame(stringsAsFactors = FALSE)
docs.nres<-data.frame(stringsAsFactors = FALSE)
docs[[1]][[3]]
docs[[1]]
docs[[1]][[1]]
docs[[1]][[2]]
i<-1
docs[[i]][[3]]<-sent_detect(docs[[i]][[1]])
docs[[i]][[4]]<-word_count(docs[[i]][[3]])
docs[[i]][[3]]<-data.frame(text=docs[[i]][[3]],stringsAsFactors = FALSE)
install.packages("tm.lexicon.GeneralInquirer", repos="http://datacube.wu.ac.at", type="source")
library(tm.lexicon.GeneralInquirer)
install.packages("tm.plugin.sentiment", repos="http://R-Forge.R-project.org")
library(tm.plugin.sentiment)
library(tm.plugin.sentiment)
install.packages("tm.plugin.sentiment", repos="http://R-Forge.R-project.org")
library(tm.plugin.sentiment)
library(devtools)
install_github("mannau/tm.plugin.sentiment")
library(tm.plugin.sentiment)
pos <- sum(sapply(Q1.doc, tm_term_score, terms_in_General_Inquirer_categories("Positiv")))
View(Q1)
Q1
c(Q1)
as.vector(Q!)
as.vector(Q1)
Q1.doc<-Corpus(VectorSource(as.vector(Q1)))
pos <- sum(sapply(Q1.doc, tm_term_score, terms_in_General_Inquirer_categories("Positiv")))
?tm_term_score
pos.score <- tm_term_score(TermDocumentMatrix(Q1.doc, control = list(removePunctuation = TRUE)),
terms_in_General_Inquirer_categories("Positiv"))
neg.score <- tm_term_score(TermDocumentMatrix(Q1.doc, control = list(removePunctuation = TRUE)),
terms_in_General_Inquirer_categories("Negativ"))
total.df <- data.frame(positive = pos.score, negative = neg.score)
View(total.df)
total.df <- transform(total.df, net = positive - negative)
pos.score <- tm_term_score(TermDocumentMatrix(Q1.doc, control = list(removePunctuation = TRUE)),
terms_in_General_Inquirer_categories("Positiv"))
pos.score <- tm_term_score(TermDocumentMatrix(Q1.doc, control = list(removePunctuation = TRUE)),
terms_in_General_Inquirer_categories("Positiv"))
neg.score <- tm_term_score(TermDocumentMatrix(Q1.doc, control = list(removePunctuation = TRUE)),
terms_in_General_Inquirer_categories("Negativ"))
Q1.df <- data.frame(positive = pos.score, negative = neg.score)
Q1.df <- data.frame(positive = pos.score, negative = neg.score)
Q1.df <- transform(Q1.df, net = positive - negative)
View(Q1.df)
pos.score <- tm_term_score(TermDocumentMatrix(Q2.doc, control = list(removePunctuation = TRUE)),
terms_in_General_Inquirer_categories("Positiv"))
neg.score <- tm_term_score(TermDocumentMatrix(Q2.doc, control = list(removePunctuation = TRUE)),
terms_in_General_Inquirer_categories("Negativ"))
Q2.sentiment <- data.frame(positive = pos.score, negative = neg.score)
Q2.sentiment <- transform(Q2.sentiment, net = positive - negative)
View(Q1.num)
View(Q2.num)
feature<-data.frame()
Q1.doc[[2]]
Q1.doc[[1]]
Q1.doc[[1]][[1]]
Q1.doc[[1]][[2]]
?split
word.count<-function(sent){
text<-sent[[1]]
word<-split(text," ")
return(length(word[[1]]))
}
text<-Q1.doc[[1]][[1]]
word<-split(text," ")
length(word[[1]]))
length(word[[1]])
word
word<-split(text," ")
word
split()
?split
word<-strsplit(text," ")
word
length(word[[1]])
text.count<-function(sent){
text<-sent[[1]]
punc<-length(gregexpr("[.|!|?|;|:|,]",text)[[1]])
modal<-length(gregexpr("will|can|shall|must|should|would|could|may|might",text)[[1]])
neg<-length(gregexpr("never|not|non|rare|no|neither|seldom|hardly",text)[[1]])
word<-strsplit(text," ")
return(list(punc=punc,modal=modal,neg=neg,word=length(word[[1]])))
}
Q1.num<-llply(Q1.doc,text.count)
Q1.num<-llply(Q1.doc,text.count)
Q1.num<-llply(Q1.doc,text.count)
Q1.num<-ldply(Q1.num,unlist)
Q2.num<-llply(Q2.doc,text.count)
Q2.num<-ldply(Q2.num,unlist)
View(Q2.sentiment)
View(Q2.num)
pos.score <- tm_term_score(TermDocumentMatrix(Q1.doc, control = list(removePunctuation = TRUE)),
terms_in_General_Inquirer_categories("Positiv"))
neg.score <- tm_term_score(TermDocumentMatrix(Q1.doc, control = list(removePunctuation = TRUE)),
terms_in_General_Inquirer_categories("Negativ"))
Q1.sentiment <- data.frame(positive = pos.score, negative = neg.score)
Q1.sentiment <- transform(Q1.sentiment, net = positive - negative)
feature<-data.frame()
feature$punc<-Q2.num$punc/Q1.num$punc
feature<-data.frame()
feature$punc<-Q2.num$punc-Q1.num$punc
Q2.num$punc-Q1.num$punc
data.frame
?data.frame
feature<-data.frame(punc=Q2.num$punc-Q1.num$punc)
View(feature)
feature$modal<-(Q2.num$modal-Q1.num$modal)/(Q1.num$word+Q2.num$word)
feature$length<-(Q2.num$word-Q1.num$word)/(Q1.num$word+Q2.num$word)
feature$neg<-(Q2.num$neg-Q1.num$neg)/(Q1.num$word+Q2.num$word)
feature$sentiment<-Q2.sentiment$net-Q1.sentiment$net
feature$positive<-Q2.sentiment$positive-Q1.sentiment$positive
feature$negative<-Q2.sentiment$negative-Q1.sentiment$negative
write.csv(feature,file = "../output/feature_lyq.csv")
